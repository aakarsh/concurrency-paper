% Created 2014-04-04 Fri 19:09
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{soul}
\usepackage{textcomp}
\usepackage{marvosym}
\usepackage{wasysym}
\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{listings}

\tolerance=1000
\providecommand{\alert}[1]{\textbf{#1}}

\title{Synchronization in Linux}
\author{Aakarsh Nair}
\date{\today}

\begin{document}
\lstset{language=C}  
\maketitle

\setcounter{tocdepth}{3}
\tableofcontents

\maketitle
%%\addcontentsline{toc}
\vspace*{1cm}

\section{Introduction}

Syncronization becomes necessary when the outcome of a computation
depends on how two or more interleaved kernel control paths are
nested. Critical regions are parts of code that must be executed by at
most one kernel coltrol path to completion before another kernel
control path is allowed to execute it.

\section{Kernel Preemption}

Process running in Kernel Mode can be replaced by another
process. Process switches happens via the \lstinline{switch_to_macro}.

Kernel premption is enabled and disabled via the
\lstinline{prempt_count} in the \lstinline{thread_info}.

It is greater than zero if 

\begin{itemize}
\item The kernel is executing in an interrupt service routine.
\item kernel is executing a tasklet of a softirq
\item kernel preemption has been explictly disabled setting it to a
  positive value
\end{itemize}

\section{Kernel Syncrhonization Primitives}

The linux kernel provides several synchronization primitives these
include

\begin{itemize}
\item \textbf{Per-CPU variables}
  Use duplicate data structures for each cpu
\item \textbf{Atomic Operations}
  Attomically read-modify-write instruction to a counter
\item \textbf{Memory Barrier}
  Avoid instruction reordering
\item  \textbf{Spinlock}
  Lock with a busy wait
\item \textbf{Semaphores}
  Lock with blocking wait/sleep.
\item \textbf{Seqlocks}
  Lock based on access counter
\item \textbf{Local interrupt disabling}
  Forbid interrupt handling on a single CPU
\item \textbf{Local softirq disabling}
  Forbid deferrable function handling on a single CPU
\item \textbf{Read Copy Update}
  Lock free access to shared data structures using pointers
\end{itemize}

Many of these synchronization constructs depend on implementation of
atomic operations implementd at the chip level on CPUs. Thus are
specific to the architecture they are executing on.

\subsection{Processor guarantees}

\begin{itemize}
  \item On a particular CPU dependent memory accesses happen in order
    of issuance.

  \item Overlapping loads and stores within a particular CPU will
    apear to be ordered within a CPU
    
\end{itemize}

Things which cannot be assumed

\begin{itemize}
\item it \textbf{must not} be assumed that compilers will not reorder
  memory references not protected with ACCESS\_ONCE(). Without
  ACCESS\_ONCE() the compiler can perform tranformations see memory
  barriers.
\item it \textbf{must not} be assumed that independent loads and
  stored will be issued in any given order.
\item it \textbf{must not} be assumed that overlapping memroy accesses
  may be merged or discarded.  
\end{itemize}

Things that we anti-guarantees (bad stuff will happen):

\begin{itemize}


\item Compilers will often genrate code to modify bit fields using non
  atomic read-modify write sequences


\item All fieds in a given bitfield must be must be protected by one
  lock. Update of one field can be corrupted by another by compiler.
  
\item Gaurantees only apply to properly aligned and sized scalar
  variables. Same size as "char","short","int" and "long".  


\end{itemize}

\subsection{Memory Barrier}

Memroy barriers impose perceived partial ordering over memroy
operations on either side of the barrier.

Memory barriers provide a way to instruct the compiler and CPU to
restrict the order in which instructions are executed. Performance
optimizations of compilers and CPUs play havoc with synchronization
primitives. These include compiler reordering instructoins to optimize
register usage, CPUs executing instructions in parallel, reordering
memory accesses.


Types of performance tricks memory barriers may protect against are
\begin{itemize}
\item reordering and defferral of combination of memory operations
\item sepculative loads
\item sepculative branch prediction and caching
\end{itemize}

Memroy barrier types include
\begin{itemize}
\item Write (or store) memory barrier

  A write memory barrier gives gauratnee that all STORE operations
  specified before the barrier will happen before all STORE operations
  STORE oeprations specified after the barrier. wrt other components
  in the system.

  A partial order on STORES only. Does not affect LOADS.

  CPU can be viewed as performing a commit. All stores before the
  write barrier will occur before all stores after the write barrier.

  Should not be paired with read or data dependency barrier.
  
\item Data dependency barrier

  Weaker form of read barrier. Two loads such that the the second
  depnds on result of first ( first load retreives the address which
  to which second load is directed). Ensure the target of second load
  is updated before first load accessed (??)

  Partial ordering on inter-dependent loads only. No effect on
  independent loads or overlapping loads.


  TODO - need to look into this deeper.


\item Read (or load) memory barrier  

  
  
\item General Memory barrier

  All LOAD and STORE operations before the barrier will happen before
  all LOAD and STORE operations specified after the barrier with
  respect to other components of the system.

  A partial ordering over both loads and stores.  

\item Implicet Barriers
  \begin{itemize}
  \item ACQUIRE operations
  \item RELEASE operations
  \end{itemize}
\end{itemize}



\subsection{CPU Memory Barriers}

All memory barriers except datadependecy barriers imply compiler
barrier. SMP memory barriers are reduced to compier barriers on
uniprocessor compiled systems. 


\begin{itemize}

\item{Optimization barrier} Can be implemented using the
  \emph{barrier()} macro expanding to \emph{asm volatile"":::memory}

  Tells the compiler to insert empty assembly fragment. While the
  volatile keyword forbids the compiler from shuffling the
  instruction.  The memory keyword forces the compiler to use memory
  locations instead of those stored in the register. The CPU can still
  mix assembly instruction


  
  
\item{Memory barrier}

  In 80x86 list of serializing instructions which act as memory
  barriers:


  \begin{itemize}
    \item I/O port operations
    \item instructions with lock byte
    \item instructions affecting the IF flag in eflags register such as those instructions which write to registers
      \begin{itemize}
        \item control registers (cli)
        \item system  registers (sti)
        \item debug   registers          
      \end {itemize}
    \item Some instructions introduced in Pentium 4
      \begin{itemize}
        \item lfence - read barriers
        \item sfence - write barries
        \item mfence - read write barriers
      \end{itemize}
    \item Speial instructions - iret terminating interrupt or exception handler                  
  \end{itemize}
  
\end{itemize}

Read barriers maintain the serial order of read instructions, write
barriers maitain serial order of write instructions.

\begin{center}
  \begin{tabular}{ l | l }    
    \hline
    Function/Macors & Description \\ \hline
    mb() & Memory barrier for MP and UP \\ 
    rmb() & Read memory barrier for MP and UP  \\ 
    wmb() &  Write memory barrier for MP and UP \\
    smp\_mb() &  Memory barrier for MP only \\
    smp\_rmb() &  Read memory barrier for MP only \\
    smp\_wmb() &  Write memory barrier for MP only \\
    \hline
  \end{tabular}
\end{center}
  Macro expansions on  80x86

  \begin{center}
  \begin{tabular}{ l | l }    
    \hline
    Function/Macors & Description \\ \hline
    mb() &  \\ 
    rmb() & asm volatile ("lfence") or asm volatile ("lock;addl 0,0(\%\%esp)":::"memory")  \\ 
    wmb() & barrier()- intel never reorders write memory access only need an optimization barrier  \\
    smp\_mb() &   \\
    smp\_rmb() &  \\
    smp\_wmb() &  \\
    \hline
  \end{tabular}
\end{center}

All atomic operaitions act as memory barriers since they use the lock byte.

\subsection{Atomic Operations}

Atomic read-modify-write instructions are executed atomically by a CPU
hardware via a single instruction which is executed without
interruptions by other CPUs.

\subsubsection{Atomic Operations 80x86}

\begin{itemize}
  \item Read-modify-write assembly instructions such as inc and dec
    that read data from memory and update it are atomic , provided
    stale data has not been read by another processor. This is the
    case in uniprocessor systems.

  \item Read-modify-write instructions whose opcode is prefixed by the
    \emph{lock byte} (\emph{0xf0}) are atomic on multiprocessor
    systems.  The lock byte will lock access to the mememory bus until
    the locking instruction finishes its operation.
  \item Instructions prefixed by the \emph{rep} byte \emph{0xf2,0xf3}
    which forces instructions to be repeated are not atomic since the
    CPU checks interrupts before each iteration.

\end{itemize}



\subsection{Spinlock}

  \begin{center}
  \begin{tabular}{ l | l }    
    \hline
    Function/Macors & Description \\ \hline
    spin\_lock\_init() & Set spin lock to 1 (unlocked) \\ 
    spin\_lock() & Cycle until spinlock becomes 1(unlocked) then set it to 0 (locked) \\ 
    spin\_unlock() & Set the spin lock to 1 (unlocked) \\
    spin\_unlock\_wait() & Wait until the spinlock becomes 1 (unlocked)  \\
    spin\_is\_locked() & Return 0 if the spinlock is set to 1(unlocked) ; 1 otherwise  \\
    spin\_trylock() &  Set the spin lock to 0 (locked), and return 1 if the previous value of the lock was 1; 0 otherwise\\
    \hline
  \end{tabular}
  \end{center}

  \subsubsection{The spin\_lock macro with kernel preemption}

  \begin{itemize}
    \item Invoke \emph{preeempt\_disable()} dsiable kernel preemption
    \item Invoke \emph{\_raw\_spin\_trylock()} atomic test and set on
      spinlock's \emph{slock} field.

      \emph{moveb \$0,\%a1}
      \emph{xchgb \%a1,slp->slock}

      \emph{xchg} echange atomically content of 8-bit \%a1 with slp->slock.
      return 1 if old value was positive or 0 otherwise.

    \item If old value of spin lock was positve, we have acquired the spinlock
        
    \item If failed then spin lock was not positive , invoke
      \emph{preempt\_enable()} decrement the preeempt counter. which
      if it goes to zero willl allow the process to be scheduled out,

    \item set the \emph{break\_lock} field to to one. Allow another
      process to release spin lock prematurely

    \item Execute the wait cycle
      \begin{lstlisting}
      while(spin_is_locked(slp) && slp->break_lock)
          cpu_relax(); // special pause instruction Pentium 4
      \end{lstlisting}
    \item Jump back to step 1 
      
  \end{itemize}


  



\subsection{Semaphores}




\subsection{Per-CPU Variables}

A per-CPU variable is an array of datastructures one per cpu. Each CPU
can read and modify its own elements without race.

These are aligned in main memory so that each one falls in different
line of hardware cache. Concurrent access does not lead to cache line
snooping and invalidation.

Though per-cpu variables allow for data structures to be protected
against different CPUS they cannot be used to protect against
asynchronous accesses coming through the same CPU.

Accessing a per-CPU variable needs to be aware that premption might
cause the process to get migrated onto another CPU and thus it might
be advisable to turn off preemptions for per CPU variables.


\begin{center}
  \begin{tabular}{ l | l }
    
    \hline
    Function/Macors & Descriptions \\ \hline
    DEFINE\_PER\_CPU(type,name) & Statically Allocate a per-CPU called type \\ 
    per\_cpu(name,cpu) & Selects element for CPU cpu \\ 
    get\_cpu\_var(name) &  Disables kernel premeption \\
    put\_cpu\_var(name) &  Re-enables kernel premeption \\
    alloc\_percpu(ptr) &  dynamcally allocatee cpu variable \\
    free\_percpu(ptr) &  Release a dynamcally allocated cpu variable \\
    \hline
  \end{tabular}
\end{center}

\section{MESI Cache Coherency Protocol}

Cache-coherency protocls manage cache-line states to prevent
inconsitent states or lost data. MESI stats for "modified",
"exclusive", "shared" and "invalid". Which represent the four states
assigned to cache lines in this protocol.The MESI protocol is a
protocol used to implement cache and memory coherency amongst multiple
CPUs. \cite{Birdetal2001}

Two bits are added to each cache line which represent the four states
that a cache line can be in.

\begin{itemize}
\item Modified
  \begin{itemize}
    \item Cache Line is present only on current CPU
    \item Cache Line has been modified
    \item Write back needs to be performed
  \end{itemize}


\item Exclusive
    \begin{itemize}
    \item Cache Line is present only in current CPU
    \item Cache Line is cliean (matches main memory)
    \end{itemize}
    
  \item Shared
    \begin{itemize}
    \item Cache Line is present in multiple CPUs
    \item Cache Line is Clean (matches main memory)
    \end{itemize}
  \item Invalid 
\end{itemize}

\subsection{MESI Protocol messages}

If the CPUs are on a single shared bus we only require the following
messages on the bus.

\begin{itemize}
\item \textbf{Read} Content : physical address of cache line to be
  read.
\item \textbf{Read Response} Response with data, Source : Memory or
  one of the other caches. If the other cache has data in modified
  state.
\item \textbf{Invalidate} Content : Address of cache line to be
  invalidated. All other caches must invalidate cache line with this
  address.

\item \textbf{Invalidate Acknowledge} From: CPU that has invalidated a
  cache line.

\item \textbf{Read Invalidate} Content: Read cache line and take
  ownership of it getting the cache line removed from other
  processors. Combination of read and invalidate. Responses are read
  response and invalidate acknowledge

\item \textbf{Writeback} contnet: Address of and data of write back to
  memory. This message might get snooped by other processors to mark
  cache lines as "modified"  
\end{itemize}

Thus we see the fractal nature of distributed system where message
passing is implemented at different levels of the systems
architecture.


\subsection{MESI Transitions Table}

We give a tabular description of transitions involved in the MESI
protocl.


\begin{center}
\begin{tabular*}{0.75\textwidth} {| l | l | l | l| }    
    \hline
    & Start  & End   & Descriptions \\
    \hline
    a & Modified  & Exclusive &
    Cache line is written back to memmory but CPU retains exclusive 
    owner ship of and right to modify it. Requires "writeback" 
    message\\
    \hline
    b& Exclusive & Modified &  
    CPU writes to exclusive cache line. No messages required. \\
    \hline
    c & Modified & Invalid &   
    CPU receives a "read invalidate" for a cache line it modified.It 
    must invalidate the local copy, send an read response and a 
    invalidate acknowledge \\
    \hline
    d & Invalid & Modified &
    An atomic read-modify-write operation on a data item not present
    in the cache. Transmits a "read invalidate" response and gets
    "read response". Cannot proceed until all cpus reply with
    "invalidate acknowledge" response.    \\


    \hline
    e & Shared & Modified & 

    CPU does read-modify write one data item that was
    read-only. Transmits a "invalidate" messagee. Wait for invalidate
    acknowlege from all other CPUs.    


    \\
    \hline
    f & Modified & Shared &

    Some other CPU reads from our cache line suplied from this
    CPU. This CPU responds with a "read response" message.    
    \\    
    \hline

    g & Exclusive & Shared & 

    Some other CPU reads data in this cache line 
    
    \\
    \hline

    h & Shared & Exclusive & k \\
    \hline

    i & Exclusive & Invalid & k \\
    \hline

    j & Invalid & Exclusive & k \\
    \hline

    k & Invalid & Shared & k \\
    \hline

    l & Shared & Invalid & k \\
    \hline
    
  \end{tabular*}
\end{center}





\begin{thebibliography}{9}

\bibitem{ia32-sys}
  \textit{IA-32 Intel Architecture Software Developer's Manual, Volume 3:
    System Programming Guide} \\
  \textit{Chapter 7.1: Locked Atomic Operations} \\
  \textit{Chapter 7.2: Memory Ordering}  \\
  \textit{Chapter 7.4: Serializing Instructions}

\bibitem{unix-ma}
  \textit{Unix Systems for Modern Architectures, Symmetric Multiprocessing and Caching
    for Kernel Programmers} \\
  \textit{Chapter 13: Other Memory Models}  
  
\bibitem{mesi-wikipedia} 
  \textit{MESI protocol} 
  \url{http://en.wikipedia.org/wiki/MESI_protocol}
\bibitem{cache-coherency-primer} 
   \textit{Cache Coherency Primer}  \textit{Fabian “ryg” Giesen} \\
   \url{https://fgiesen.wordpress.com/2014/07/07/cache-coherency/}

 \bibitem{atomic-operations}
   \textit{Atomic Operations - CSE 378 University of Washington} \\
  \url{http://courses.cs.washington.edu/courses/cse378/07au/lectures/L25-Atomic-Operations.pdf}
\bibitem{memory-barriers}
  \textit{Linux Kernel Memory Barriers}
  \url{https://www.kernel.org/doc/Documentation/memory-barriers.txt}
\bibitem{columbia-sync-linux}
  \textit{Synchronization in Linux}
  \url{http://www.cs.columbia.edu/~junfeng/10sp-w4118/lectures/l11-synch-linux.pdf}

\bibitem{under-linux-kernel-sync}
  \textit{Understanding the Linux Kernel - Chapter 5} \\
  \textit{David Bovet and Marco Cesati}  

\bibitem{sadc}  
  \textit{Structures and Design of Computers } \\
  \textit{David E. Patterson and J.L. Hennessey} 
  

\end{thebibliography}

\end{document}


%% "I want to solve problems, but I want to solve my problems. I don't
%% want to go looking for other people's problems to solve."
%%
%% - Linus
